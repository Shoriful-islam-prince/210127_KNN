import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns


from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
f1_score, roc_auc_score, roc_curve,
confusion_matrix)

github_raw_url = "https://raw.githubusercontent.com/Shoriful-islam-prince/210127_KNN/main/heart_disease_data.csv"
df = pd.read_csv(github_raw_url)
df.head()

df.info()

df.isnull().sum()


df.fillna(df.median(numeric_only=True), inplace=True)




df.head()

from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()

for col in df.select_dtypes(include='object').columns:
    df[col] = encoder.fit_transform(df[col])

print(df.shape)
print(df.columns)

X = df.drop('target', axis=1) # ensure column name is correct
y = df['target']

df.fillna(df.median(numeric_only=True), inplace=True)

X = df.drop('target', axis=1)
y = df['target']

from sklearn.preprocessing import StandardScaler


scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

df.isnull().sum()

from sklearn.model_selection import train_test_split


X_train, X_temp, y_train, y_temp = train_test_split(
X_scaled, y, test_size=0.3, random_state=42, stratify=y
)


X_val, X_test, y_val, y_test = train_test_split(
X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
)

from sklearn.neighbors import KNeighborsClassifier


knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)

from sklearn.metrics import accuracy_score


y_val_pred = knn.predict(X_val)
accuracy_score(y_val, y_val_pred)

from sklearn.metrics import accuracy_score




y_val_pred = knn.predict(X_val)
accuracy_score(y_val, y_val_pred)

from sklearn.model_selection import GridSearchCV


param_grid = {
'n_neighbors': [3,5,7,9,11],
'weights': ['uniform', 'distance'],
'metric': ['euclidean', 'manhattan', 'minkowski']
}


grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)
grid.fit(X_train, y_train)


grid.best_params_

best_knn = grid.best_estimator_
best_knn.fit(X_train, y_train)





y_test_pred = best_knn.predict(X_test)
y_test_prob = best_knn.predict_proba(X_test)[:,1]

from sklearn.metrics import confusion_matrix


sns.heatmap(confusion_matrix(y_test, y_test_pred), annot=True, fmt='d')
plt.title('KNN Confusion Matrix')
plt.show()

from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score


print('Accuracy:', accuracy_score(y_test, y_test_pred))
print('Precision:', precision_score(y_test, y_test_pred))
print('Recall:', recall_score(y_test, y_test_pred))
print('F1:', f1_score(y_test, y_test_pred))
print('AUC:', roc_auc_score(y_test, y_test_prob))

from sklearn.metrics import roc_curve


fpr, tpr, _ = roc_curve(y_test, y_test_prob)


plt.figure()
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('KNN ROC Curve')
plt.show()

from sklearn.decomposition import PCA


pca = PCA(n_components=2)
X_2d = pca.fit_transform(X_scaled)


X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split(
X_2d, y, test_size=0.2, random_state=42
)


knn_2d = KNeighborsClassifier(n_neighbors=best_knn.n_neighbors)
knn_2d.fit(X_train_2d, y_train_2d)

from mlxtend.plotting import plot_decision_regions


plot_decision_regions(X_test_2d, y_test_2d.values, clf=knn_2d)
plt.title('KNN Decision Boundary (2D)')
plt.show()

